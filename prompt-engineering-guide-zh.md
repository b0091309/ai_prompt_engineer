# Prompt 工程指南（中文翻譯）

> 原文來源：https://www.promptingguide.ai/

---

## 目錄

1. [簡介](#簡介)
2. [提示基礎](#提示基礎)
3. [提示元素](#提示元素)
4. [設計提示的通用技巧](#設計提示的通用技巧)
5. [提示技術](#提示技術)
   - [零樣本提示 (Zero-shot Prompting)](#零樣本提示-zero-shot-prompting)
   - [少樣本提示 (Few-shot Prompting)](#少樣本提示-few-shot-prompting)
   - [思維鏈提示 (Chain-of-Thought)](#思維鏈提示-chain-of-thought)
   - [檢索增強生成 (RAG)](#檢索增強生成-rag)
   - [ReAct 框架](#react-框架)
   - [Self-Consistency（自我一致性）](#self-consistency自我一致性)
   - [Generate Knowledge Prompting](#generate-knowledge-prompting生成知識提示)
   - [Prompt Chaining（提示鏈）](#prompt-chaining提示鏈)
   - [Tree of Thoughts（思維樹）](#tree-of-thoughts思維樹)
   - [Meta Prompting（元提示）](#meta-prompting元提示)
   - [APE（自動提示工程師）](#automatic-prompt-engineerape自動提示工程師)
   - [Active-Prompt（主動提示）](#active-prompt主動提示)
   - [ART（自動推理與工具使用）](#art自動推理與工具使用)
   - [Directional Stimulus Prompting](#directional-stimulus-prompting方向性刺激提示)
   - [PAL（程式輔助語言模型）](#pal程式輔助語言模型)
   - [Reflexion（反思）](#reflexion反思)
   - [Multimodal CoT（多模態思維鏈）](#multimodal-cot多模態思維鏈)
   - [Graph Prompting（圖提示）](#graph-prompting圖提示)
   - [技術選擇指南](#技術選擇指南)
6. [AI Agents（AI 代理）](#ai-agents-ai-代理)
   - [什麼是 AI Agent](#什麼是-ai-agent)
   - [Agent 核心組件](#agent-核心組件)
   - [上下文工程](#上下文工程)
   - [函數調用](#函數調用)
7. [應用案例](#應用案例)
8. [模型指南](#模型指南)
   - [OpenAI 系列](#openai-系列)（ChatGPT、GPT-4）
   - [Anthropic 系列](#anthropic-系列)（Claude 3）
   - [Google 系列](#google-系列)（Gemini、Gemma）
   - [Meta 系列](#meta-系列)（LLaMA、Llama 3、Code Llama）
   - [Mistral AI 系列](#mistral-ai-系列)（Mistral 7B、Mixtral）
   - [其他模型](#其他模型)（Phi-2、Flan、Grok-1、OLMo、Sora）
   - [模型選擇指南](#模型選擇指南)

---

## 簡介

**Prompt 工程**（提示工程）是一門相對較新的學科，專注於開發和優化提示，以便高效地使用大型語言模型（LLM）進行各種應用和研究。

Prompt 工程技能有助於更好地理解大型語言模型的能力和限制。研究人員利用 prompt 工程來提升 LLM 在各種常見和複雜任務（如問答和算術推理）上的能力。開發人員則使用 prompt 工程來設計與 LLM 及其他工具互動的穩健且有效的提示技術。

Prompt 工程不僅僅是關於設計和開發提示。它涵蓋了與 LLM 互動和開發所需的廣泛技能和技術。這是一項重要的技能，用於與 LLM 互動、構建和理解其能力。你可以使用 prompt 工程來提高 LLM 的安全性，並構建新的功能，如使用領域知識和外部工具來增強 LLM。

---

## 提示基礎

### 基本概念

提示（Prompt）可以包含以下任何元素：
- **指令**：你希望模型執行的特定任務
- **問題**：你想要得到回答的問題
- **上下文**：外部資訊或額外的背景
- **輸入資料**：需要處理的輸入
- **範例**：展示期望輸出的示例

### 基本提示方法

**簡單提示**

最簡單的提示就是直接向模型提問：

```
什麼是 prompt 工程？
```

**帶格式的提示**

使用特定格式可以獲得更好的結果：

```
問：什麼是 prompt 工程？
答：
```

**帶上下文的提示**

提供更多上下文可以引導模型產生更好的回應：

```
完成以下句子：天空是
```

比起只說「天空是」，這種格式更能引導模型產生完整的回應。

### 核心原則

> 語言模型輸出結果的品質，取決於你提供的資訊量以及提示設計的精良程度。

---

## 提示元素

一個有效的提示可以包含以下四個核心元素：

### 1. 指令 (Instruction)

你希望模型執行的具體任務或指令。例如：「分類」、「翻譯」、「摘要」等。

### 2. 上下文 (Context)

可以引導模型產生更好回應的外部資訊或額外背景。這可以包括相關的背景知識、限制條件或特定的領域資訊。

### 3. 輸入資料 (Input Data)

我們想要找到回應的輸入或問題。這是需要模型處理的主要內容。

### 4. 輸出指示器 (Output Indicator)

輸出的類型或格式。這可以指定你期望的回應格式，如列表、JSON、特定長度等。

### 實際範例

以下是一個包含多個元素的情感分類任務：

```
將以下文字分類為中性、負面或正面。

文字：我覺得這食物還可以。

情感：
```

在這個範例中：
- **指令**：「將以下文字分類為中性、負面或正面」
- **輸入資料**：「我覺得這食物還可以」
- **輸出指示器**：「情感：」

> **注意**：並非每個提示都需要包含所有四個元素。結構取決於你的具體使用情境。

---

## 設計提示的通用技巧

### 1. 從簡單開始

設計提示是一個需要大量實驗的迭代過程。建議從簡單的提示開始，隨著你追求更好的結果逐步添加更多元素和上下文。將大任務分解為更簡單的子任務，逐步構建。

### 2. 使用清晰的指令

使用明確的命令詞來告訴模型你想要它做什麼，例如：
- 「撰寫」
- 「分類」
- 「摘要」
- 「翻譯」
- 「排序」

將指令放在提示的開頭，並使用分隔符號（如 `###`）來分隔指令和上下文。

### 3. 具體明確

越詳細和描述性越好。具體說明你想要的輸出格式、長度、風格等。但要注意避免不必要的細節——保持資訊與任務相關。

### 4. 避免模糊不清

與其過於聰明或含糊，不如直接和清晰。例如：

❌ 不好的寫法：「解釋要簡短，只要幾句話」

✅ 好的寫法：「使用 2-3 句話解釋」

### 5. 說明該做什麼，而非不該做什麼

盡量用正面的指令描述期望的行為，而不是用否定句描述不希望的行為。

❌ 不好的寫法：「不要詢問用戶的興趣」

✅ 好的寫法：「根據熱門電影直接推薦，無需詢問偏好」

### 6. 持續迭代和實驗

測試不同的關鍵字、上下文和格式，找出最適合你特定使用情境的方法。Prompt 優化需要持續的改進和調整。

---

## 提示技術

### 零樣本提示 (Zero-shot Prompting)

**定義**：直接要求模型完成任務，不提供任何示例。

**特點**：
- 最簡單的提示方法
- 依賴模型的預訓練知識
- 適合簡單、直接的任務

**範例**：
```
將以下文字分類為正面或負面。

文字：這部電影太精彩了！

分類：
```

### 少樣本提示 (Few-shot Prompting)

**定義**：透過在提示中提供幾個示例來進行上下文學習（in-context learning），引導模型產生更好的回應。

**特點**：
- 提供範例讓模型學習模式
- 適合需要特定格式或風格的任務
- 通常比零樣本提示效果更好

**範例**：
```
這太棒了！ // 正面
這太糟糕了！ // 負面
那部電影很精彩！ // 正面
多麼可怕的節目！ //
```

**重要發現**（Min et al., 2022）：
- **標籤空間很重要**：示例中使用的標籤和輸入文字的分布都很重要
- **格式一致性有幫助**：即使使用隨機標籤，保持格式結構也能改善結果
- **分布選擇**：使用真實的標籤分布比隨機均勻分布效果更好

**限制**：
- 對於複雜的推理任務效果有限
- 這種情況下建議使用思維鏈提示或其他進階技術

### 思維鏈提示 (Chain-of-Thought)

**定義**：透過中間推理步驟來實現複雜推理能力的提示技術（Wei et al., 2022）。

**核心方法**：

#### 1. 標準 CoT 提示

結合少樣本學習，在提示中展示完整的推理步驟：

```
問：這組數字中的奇數加起來是偶數還是奇數：4, 8, 9, 15, 12, 2, 1。
答：所有奇數（9, 15, 1）相加，9 + 15 + 1 = 25。答案是奇數。

問：這組數字中的奇數加起來是偶數還是奇數：17, 10, 19, 4, 8, 12, 24。
答：
```

#### 2. 零樣本 CoT

只需添加「讓我們一步一步思考」（Let's think step by step）這個簡單的提示詞：

```
問：我去市場買了10個蘋果。我給了鄰居2個蘋果，給了修理工2個蘋果。然後我又去買了5個蘋果，吃了1個。我還剩幾個蘋果？

答：讓我們一步一步思考。
```

#### 3. 自動 CoT (Auto-CoT)

自動化生成推理鏈的方法（Zhang et al., 2022）：
- 將問題進行聚類分組
- 從各群中選擇代表性問題
- 自動生成推理鏈

**最佳實踐**：
- 提供多樣化的範例以提高準確性
- 使用簡單且清晰的推理步驟
- 對於無示例情況，使用零樣本 CoT
- 強調逐步思考過程而非直接答案

### 檢索增強生成 (RAG)

**定義**：RAG 是一種將資訊檢索元件與文字生成模型結合的方法。它接收輸入，從來源（如 Wikipedia）檢索一組相關/支援性文件，並將它們作為上下文來生成輸出。

**核心優勢**：
- **增強事實準確性**：生成的回應更加準確
- **減少幻覺**：降低語言模型產生虛假資訊的機率
- **存取最新資訊**：無需重新訓練即可使用當前資訊

**運作方式**：
1. 接收使用者的查詢
2. 從知識庫中檢索相關文件
3. 將檢索到的文件作為上下文補充原始提示
4. 生成基於檢索內容的回應

**效能與應用**：
- 在 Natural Questions 和 WebQuestions 等基準測試中表現良好
- 生成的回應「更加事實準確、具體且多樣化」
- 現代實作常與 ChatGPT 等 LLM 結合使用

### ReAct 框架

**定義**：ReAct 以交錯的方式結合推理（Reasoning）和行動（Acting）。LLM 同時生成「推理軌跡」和「任務特定行動」，使模型能夠與外部資訊來源互動，同時保持可解釋的推理過程。

**運作方式**：
透過思考-行動-觀察（Thought-Action-Observation）的循環步驟運作：
1. 模型生成推理來規劃下一步
2. 執行行動（如搜尋外部資料庫）
3. 觀察結果
4. 根據結果調整方法

**主要優勢**：
- **減少幻覺**：透過檢索實際資訊，而非僅依賴訓練資料
- **提高可解釋性**：展示人類可讀的推理軌跡
- **處理複雜任務**：在知識密集型和決策任務上表現出色

**效能結果**：
- 在 HotPotQA 和 ALFWorld 等任務上優於僅使用行動的方法
- 將 ReAct 與 CoT 結合通常能獲得最佳結果

**實際應用**：
LangChain 提供了內建的 ReAct 代理支援，包含搜尋 API 和計算器等工具。

### Self-Consistency（自我一致性）

**定義**：Self-Consistency 是一項進階提示工程技術（Wang et al., 2022），旨在取代思維鏈提示中使用的貪婪解碼方法。

**核心原理**：
透過少量示例的 CoT 取樣多條不同推理路徑，再從生成結果中選擇最一致的答案。

**運作步驟**：

1. **多路徑取樣**：針對同一問題生成多個推理過程
2. **結果比較**：檢視各輸出答案
3. **共識選擇**：選擇多數一致的答案（多數投票機制）

**範例**：
```
問題：當我6歲時，姐姐是我年齡的一半。現在我70歲，姐姐幾歲？

輸出1：姐姐當時3歲，年齡差3歲，所以現在是67歲。
輸出2：6的一半是3，70-3=67，姐姐67歲。
輸出3：姐姐當時3歲，現在70/2=35歲。（錯誤）

最終答案：67歲（2票 vs 1票）
```

**適用領域**：特別適合算術推理和常識推理問題。

---

### Generate Knowledge Prompting（生成知識提示）

**定義**：讓 LLM 先生成相關知識，再基於該知識做出預測的技術（Liu et al., 2022）。

**三步驟流程**：

**步驟 1：識別問題**
模型在沒有背景知識時容易出錯。

**步驟 2：生成知識**
透過提示詞引導模型產生相關背景知識：
```
輸入：希臘比墨西哥大。
知識：希臘國土面積約131,957平方公里，墨西哥國土面積約1,964,375平方公里。
```

**步驟 3：整合與預測**
將生成的知識融入新提示詞中，讓模型基於此知識給出更準確的答案。

**應用價值**：透過外部知識增強，改善模型在需要世界知識的任務表現。

---

### Prompt Chaining（提示鏈）

**定義**：將複雜任務分解為順序性的子任務，每個提示的輸出作為下一個提示的輸入。

**核心優勢**：
- **可靠性**：提升複雜任務的效能
- **透明度**：使 LLM 應用行為更可見
- **除錯性**：更容易識別問題階段
- **個人化**：適用於對話式助手

**實際應用：文件問答**

```
步驟 1 - 引文提取
提示：從以下文件中提取與問題相關的引文
      ↓
步驟 2 - 答案生成
提示：基於提取的引文生成友善、準確的回應
```

**流程圖**：
```
文件 → 提示1（提取引文）→ 引文輸出 → 提示2（生成答案）→ 最終回應
```

---

### Tree of Thoughts（思維樹）

**定義**：ToT 是一個框架，將思維過程表示為樹結構（Yao et al., 2023）。思維代表連貫的語言序列，作為解決問題的中間步驟。

**主要特徵**：
- **自我評估機制**：模型生成並評估中間思維步驟
- **搜尋演算法**：整合 BFS（廣度優先）、DFS（深度優先）或波束搜尋
- **策略性回溯**：允許探索多條推理路徑並放棄不可行的分支

**實際應用（遊戲 24）**：
```
目標：使用 4 個數字通過加減乘除得到 24

步驟1：評估候選方案
  - 方案A：8 * 3 = 24 ✓ 確定可行
  - 方案B：5 + 7 = 12 → 可能可行
  - 方案C：1 + 1 = 2 → 不可能達成

步驟2：展開可行分支
步驟3：找到最終解答
```

**簡化版本**（Hulbert, 2023）：
將概念簡化為單一提示中的評估過程，邀請多個「專家」逐步思考問題。

---

### Meta Prompting（元提示）

**定義**：強調問題的結構和語法模式而非特定內容的進階技術，創建一種抽象、結構化的方式與 LLM 互動。

**五大核心原則**：

| 原則 | 說明 |
|-----|------|
| **結構導向** | 優先考慮格式和問題模式 |
| **語法聚焦** | 使用語法作為回應模板 |
| **抽象範例** | 使用框架說明問題結構 |
| **通用性** | 可跨多個領域應用 |
| **類別方法** | 使用類型理論組織提示組件 |

**與 Few-shot 的區別**：
- Few-shot：內容驅動方法
- Meta Prompting：結構導向方法

**優勢**：
- Token 效率更高
- 公平比較（減少範例特定影響）
- 類似零樣本的能力

**適用場景**：複雜推理、數學問題、編程挑戰、理論查詢。

---

### Automatic Prompt Engineer（APE，自動提示工程師）

**定義**：APE 是一個框架（Zhou et al., 2022），將指令生成視為黑盒優化問題，使用 LLM 生成和搜尋候選解決方案。

**三階段方法**：

```
1. 生成階段
   LLM 接收輸出示範 → 創建指令候選
        ↓
2. 執行階段
   每個候選指令使用目標模型測試
        ↓
3. 選擇階段
   通過評估評分識別最有效的指令
```

**重要發現**：
APE 發現了一個更優的零樣本 CoT 提示：

> "Let's work this out in a step by step way to be sure we have the right answer."
> （讓我們一步步解決這個問題，以確保我們得到正確答案。）

這個提示在 MultiArith 和 GSM8K 基準測試中優於人類設計的「Let's think step by step」。

---

### Active-Prompt（主動提示）

**定義**：由 Diao et al. (2023) 提出，用於解決傳統思維鏈方法依賴固定人類標註範例的局限。

**核心問題**：標準 CoT 方法的範例可能不是不同任務的最有效範例。

**運作流程**：

```
1. 初步查詢
   向 LLM 提交問題 → 生成 k 個可能答案
        ↓
2. 不確定性評估
   基於 k 個回答計算不確定性（使用「不同意程度」衡量）
        ↓
3. 適應性優化
   選擇最不確定的問題 → 人類標註 → 使用新範例推論
```

**優勢**：允許系統為不同任務自動調整示例選擇。

---

### ART（自動推理與工具使用）

**定義**：ART 將思維鏈推理與工具使用整合在統一框架中（Paranjape et al., 2023）。

**運作方式**：

1. 從任務庫中選擇多步驟推理和工具示範
2. 在適當時機暫停生成以調用外部工具
3. 整合工具輸出後繼續生成

**關鍵優勢**：
> ART 鼓勵模型從示範中泛化，以零樣本方式分解新任務並在適當位置使用工具。

**效能**：在 BigBench 和 MMLU 基準測試的未見任務上，顯著優於 few-shot 提示和自動 CoT 方法。

**可擴展性**：允許人類更新任務和工具庫而無需重新訓練。

---

### Directional Stimulus Prompting（方向性刺激提示）

**定義**：一種使用可調整策略語言模型來產生刺激提示的技術（Li et al., 2023）。

**運作原理**：
- 使用較小的策略模型生成指導提示
- 優化該模型來引導凍結的黑盒 LLM
- 展現強化學習在 LLM 優化中的應用

**優勢**：相較於標準提示方式，能更有效地引導模型朝向所需的輸出方向。

---

### PAL（程式輔助語言模型）

**定義**：PAL 讓語言模型生成程式作為中間推理步驟，而非依賴自由形式的文字（Gao et al., 2022）。

**與 CoT 的關鍵區別**：
- CoT：使用自然語言推理
- PAL：利用程式碼執行環境計算解決方案

**實際範例**：
```
問題：今天是2023年2月27日。我正好在25年前出生。我的生日是什麼時候？

PAL 生成的程式碼：
from datetime import date
from dateutil.relativedelta import relativedelta

today = date(2023, 2, 27)
birthday = today - relativedelta(years=25)
print(birthday)

輸出：1998-02-27
```

**優勢**：將計算外包給程式運行環境，提高準確性。

---

### Reflexion（反思）

**定義**：Reflexion 是一個強化語言代理的框架（Shinn et al., 2023），將反饋轉換為語言反饋（自我反思），幫助代理從過往錯誤中快速學習。

**三大組成模型**：

| 組件 | 功能 |
|-----|------|
| **行為者 (Actor)** | 基於狀態觀察生成文本和行動 |
| **評估者 (Evaluator)** | 為行為者的輸出評分 |
| **自我反思** | 生成語言反饋來協助改進 |

**工作流程**：
```
定義任務 → 生成軌跡 → 評估 → 執行反思 → 生成下一軌跡
```

**實驗成果**：
- AlfWorld 決策任務：完成 130/134 個任務
- HotPotQA 推理任務：明顯超越基準方法
- HumanEval 程式碼：達到領先成果

**適用場景**：需要試錯學習、細緻反饋、重視可解釋性的任務。

---

### Multimodal CoT（多模態思維鏈）

**定義**：整合文本和視覺資訊的思維鏈方法（Zhang et al., 2023）。

**兩階段框架**：

```
階段 1：推理生成
基於多模態資訊（文字 + 圖像）生成推理過程
        ↓
階段 2：答案推論
利用生成的推理內容得出最終答案
```

**主要創新**：
- 傳統 CoT 僅專注於語言模式
- 多模態 CoT 整合文本和視覺資訊

**效能表現**：
> 1B 參數的多模態 CoT 模型在 ScienceQA 基準測試中超越了 GPT-3.5 的表現。

---

### Graph Prompting（圖提示）

**定義**：一個用於圖結構資料的新提示框架（Liu et al., 2023），旨在改善下游任務的效能。

**核心概念**：將圖結構資料與語言模型結合，處理具有結構關係的問題。

**應用場景**：
- 知識圖譜推理
- 社交網路分析
- 分子結構預測

---

### 技術選擇指南

| 任務類型 | 推薦技術 |
|---------|---------|
| 簡單分類 | Zero-shot, Few-shot |
| 數學推理 | CoT, PAL, Self-Consistency |
| 複雜決策 | Tree of Thoughts, ReAct |
| 知識密集型 | RAG, Generate Knowledge |
| 多步驟任務 | Prompt Chaining, ART |
| 需要學習改進 | Reflexion, Active-Prompt |
| 多模態問題 | Multimodal CoT |
| 結構化問題 | Graph Prompting, Meta Prompting |

---

## AI Agents（AI 代理）

### 什麼是 AI Agent

**AI Agent**（AI 代理）是指由大型語言模型（LLM）驅動的系統，設計用於**自主採取行動並解決複雜任務**。與傳統 LLM 僅能回應單一查詢不同，AI Agents 具備更強大的能力來處理需要多步驟、規劃和推理的複雜工作。

#### 為何要使用 Agent？

傳統 LLM 適合處理簡單任務（如翻譯、摘要），但難以應對需要多步驟的複雜工作。AI Agents 結合了 LLM 的文字生成能力與外部工具和記憶功能，能夠處理更複雜的任務。

#### 常見應用場景

- 推薦系統
- 客戶服務支援
- 研究調查
- 電子商務應用
- 旅遊預訂
- 數據報告與分析
- 財務分析

### Agent 核心組件

構建有效 AI Agent 的三個核心能力：

#### 1. 規劃能力（Planning）

Agent 的大腦由大型語言模型驅動，執行以下功能：

- **任務分解**：透過思維鏈推理將複雜任務分解為子任務
- **自我反思**：分析進度並從錯誤中學習
- **策略調整**：根據新資訊調整行動方案

規劃能力對於自動化複雜任務至關重要。

#### 2. 工具利用（Tool Utilization）

Agent 需要存取並適當使用外部工具，包括：

- **程式碼解釋器**：執行和分析程式碼
- **網路搜尋工具**：獲取最新資訊
- **數學計算器**：進行精確計算
- **圖像生成系統**：創建視覺內容
- **API 調用**：與外部服務互動

工具使 Agent 能將計劃轉化為具體結果。

#### 3. 記憶系統（Memory Systems）

分為兩種類型：

**短期記憶**
- 提供立即上下文
- 支援當前對話的連貫性
- 實現即時學習能力

**長期記憶**
- 透過外部向量儲存實現
- 支援快速檢索歷史資訊
- 保留跨對話的知識和經驗

這三個組件的協調作用構成了有效 AI Agent 的基礎。

### 上下文工程

**上下文工程**（Context Engineering）是為 AI Agent 設計、測試和迭代所提供的上下文資訊的過程，以塑造其行為並改善任務效能。

與單純的提示工程不同，上下文工程涵蓋：
- 系統提示設計
- 任務約束定義
- 工具描述撰寫
- 記憶管理策略
- 錯誤處理機制

#### 五大最佳實踐

**1. 消除提示歧義**

將模糊指令轉換為具體步驟序列，明確列出 Agent 必須執行的每個操作。

❌ 模糊：「處理用戶請求」

✅ 具體：「1. 解析用戶意圖 2. 查詢相關資料 3. 生成回應 4. 確認滿意度」

**2. 明確期望**

清楚指定：
- 必需與可選操作
- 質量標準
- 輸出格式
- 決策標準

**3. 實現可觀察性**

- 記錄所有 Agent 決策
- 追蹤狀態變化
- 紀錄工具調用
- 記錄錯誤和異常

**4. 基於行為迭代**

遵循循環流程：
```
部署 → 觀察 → 識別問題 → 優化 → 測試 → 部署
```

**5. 平衡靈活性與約束**

在可預測性與適應性之間找到適當平衡。過多規則導致僵化，過少規則導致不可預測。

#### 常見陷阱

| 陷阱 | 問題 |
|-----|------|
| **過度約束** | 過多規則導致系統僵化，無法適應新情況 |
| **規範不足** | 模糊指令導致不可預測的行為 |
| **忽視錯誤情況** | 缺乏故障處理協議，導致系統崩潰 |

#### 成功衡量指標

- 任務完成率
- 行為一致性
- 錯誤率
- 用戶滿意度
- 除錯時間

### 函數調用

**函數調用**（Function Calling）使 LLM 能夠與外部工具、API 和知識庫互動。模型能識別何時需要外部資料，並生成帶有正確參數的函數調用。

#### 函數調用流程

```
1. 用戶提交查詢
        ↓
2. 系統結合上下文、工具定義和用戶訊息
        ↓
3. LLM 判斷是否需要調用工具
        ↓
4. 開發者的程式碼執行實際函數
        ↓
5. 結果作為「觀察」返回給模型
        ↓
6. 模型生成包含完整上下文的最終回應
```

#### 工具定義要素

有效的工具定義應包含：

| 要素 | 說明 |
|-----|------|
| **名稱** | 清晰的識別符 |
| **描述** | 解釋用途和使用時機 |
| **參數** | 輸入項目及其類型和描述 |

#### Agent 循環

Agent 透過循環運作：

```
行動 → 環境回應 → 觀察 → 決策 → 行動 ...
```

每個循環累積上下文，使 Agent 能對後續行動做出明智決策。

#### 有效工具定義的最佳實踐

1. **使用具體描述**：包含使用情境和時機
2. **定義參數約束**：盡可能使用列舉值（enum）
3. **提供範例**：引導模型正確使用
4. **返回資訊性錯誤**：便於優雅地處理失敗
5. **在系統提示中添加使用指導**：補充工具描述

> 清晰、具體的工具定義是函數調用最關鍵的組成部分，因為它們決定了 LLM 識別哪些工具以及何時使用它們。

---

## 應用案例

Prompt 工程和 AI Agents 可應用於多種實際場景：

### 程式碼生成

使用 LLM 自動生成程式碼，包括：
- 根據自然語言描述生成函數
- 程式碼補全和建議
- 程式碼重構和優化
- Bug 修復建議

### 數據生成

- 生成合成訓練數據
- 為 RAG 系統創建測試數據集
- 處理數據集多樣性問題

### 模型微調

針對特定任務微調模型，如 Fine-tuning GPT-4o，以獲得更好的領域特定表現。

### 上下文快取

使用 LLM 的上下文快取功能優化效能和成本：
- 減少重複計算
- 提高回應速度
- 降低 API 成本

### 提示函數

將常用的提示模式封裝為可重複使用的函數，提高開發效率。

---

## 模型指南

了解不同模型的特點和限制，有助於選擇最適合任務的模型。

### 模型總覽表

| 廠商 | 模型 | 主要優點 | 主要缺點 |
|------|------|---------|---------|
| **OpenAI** | ChatGPT | 低成本、快速、大規模部署 | 事實準確性有限、推理弱 |
| | GPT-4 | 進階推理、多模態、128K 上下文 | 幻覺、成本高 |
| **Anthropic** | Claude 3 | 200K+ 上下文、長文本優異、減少幻覺 | Opus 成本高 |
| **Google** | Gemini | MMLU 人類專家水準、跨模態推理 | 需 CoT+Self-Consistency |
| | Gemini 1.5 Pro | 100 萬上下文、22 小時音頻 | 幻覺風險、提取偶有錯誤 |
| | Gemma | 數學科學編程強、開源 | 僅英語、無多模態 |
| **Meta** | LLaMA | 13B 超越 GPT-3(175B)、開源 | 需微調 |
| | Llama 3 | 70B 多數基準領先、開源 | 數學較弱、400B 未發布 |
| | Code Llama | 程式碼補全除錯、SQL | 函數調用不支援 |
| **Mistral** | Mistral 7B | 超越 Llama 2 13B、Apache 2.0 | 幻覺、提示注入風險 |
| | Mixtral 8x7B | MoE 高效、超 GPT-3.5 | 需較多資源 |
| | Mixtral 8x22B | 64K 上下文、GSM8K 90% | 模型大 |
| | Mistral Large | MMLU 81.2%、多語言 | 落後 GPT-4 |
| **Microsoft** | Phi-2 | 2.7B 超 25 倍大模型 | 冗長、非英語弱 |
| **Google** | Flan | 零樣本推理、多語言 | 任務擴展收益遞減 |
| **xAI** | Grok-1 | 314B 開源、Apache 2.0 | 未微調、需多 GPU |
| **Allen AI** | OLMo | 完全開放透明 | 文檔開發中 |
| **OpenAI** | Sora | 1 分鐘逼真視頻 | 物理模擬困難 |

---

### OpenAI 系列

#### ChatGPT (GPT-3.5-turbo)

| 特點 | 說明 |
|-----|------|
| **訓練方式** | 使用 RLHF（人類反饋強化學習）訓練 |
| **核心能力** | 對話管理、程式碼生成、內容創作、問答 |
| **成本優勢** | 相比前代版本降低 90% 成本 |

**優點**：
- 支援多輪對話和單輪任務
- 回應速度快、成本低
- 適合大規模部署

**缺點**：
- 事實準確性有限
- 知識截止日期限制
- 複雜推理能力不如 GPT-4

---

#### GPT-4

| 特點 | 說明 |
|-----|------|
| **類型** | 大型多模態模型（文字 + 圖像輸入）|
| **上下文窗口** | 128K tokens（Turbo 版本）|
| **表現** | 模擬律師考試排名前 10% |

**優點**：
- 進階推理能力和更好的對齊
- 視覺理解能力（GPT-4 Turbo with Vision）
- JSON 模式確保有效結構化輸出
- 函數調用支援（含並行調用）
- 多語言能力優於 GPT-3.5

**缺點**：
- 仍會產生幻覺和推理錯誤
- 知識截止日期（Turbo 版本為 2023 年 4 月）
- 某些推理任務需要仔細設計提示
- 成本較高

**使用建議**：使用 CoT 提示提高準確性；結合 RAG 減少幻覺；高風險決策需人工驗證。

---

### Anthropic 系列

#### Claude 3

| 版本 | 特點 |
|-----|------|
| **Haiku** | 最快、最便宜 |
| **Sonnet** | 速度提升 2 倍，平衡性能與成本 |
| **Opus** | 最強能力，在常見基準測試中超越 GPT-4 |

**優點**：
- 200K 上下文窗口（可擴展至 100 萬 tokens）
- 進階推理、數學、分析、程式碼生成
- 視覺處理（照片、圖表、圖形）
- 長文本處理：Needle In A Haystack 測試近乎完美
- 更細緻地理解請求，減少不必要的拒絕
- 改善事實準確性、減少幻覺

**缺點**：
- Opus 成本較高
- 某些任務可能過於謹慎

---

### Google 系列

#### Gemini

| 版本 | 用途 |
|-----|------|
| **Ultra** | 最強能力 |
| **Pro** | 最適合擴展 |
| **Nano** | 設備端高效運行 |

**優點**：
- 首個在 MMLU 達到人類專家水準（90.0%）的模型
- 跨模態推理（文字、圖像、視頻、音頻、程式碼）
- 視頻理解：字幕生成、問答最先進結果
- 32K 上下文長度、98% 準確率的上下文檢索

**缺點**：
- 零樣本提示在資訊提取任務上效果不完美
- 需要結合 CoT 和 Self-Consistency 才能達到最佳效果

---

#### Gemini 1.5 Pro

| 特點 | 說明 |
|-----|------|
| **架構** | 稀疏混合專家（MoE）Transformer |
| **上下文窗口** | 最高 100 萬 tokens |
| **多模態** | 文字、音頻、視頻、程式碼 |

**優點**：
- 可處理整個程式碼庫、數千頁 PDF
- 支援約 22 小時錄音或 3 小時視頻
- 訓練計算量顯著減少
- 上下文學習：僅憑文檔範例翻譯稀有語言

**缺點**：
- 幻覺風險（如 FLOPs 計算錯誤）
- 表格和文字框提取有時出錯
- 準確性因任務而異

---

#### Gemma

| 版本 | 參數量 |
|-----|--------|
| **Gemma 2B** | 20 億（使用 Multi-query Attention）|
| **Gemma 7B** | 70 億（使用 Multi-head Attention）|

**優點**：
- 數學、科學、編程表現優異
- 在 HumanEval 和 GSM8K 上超越 Llama 2 7B 和 Mistral 7B
- 開放使用、支援商業部署

**缺點**：
- 僅英語訓練（指令微調）
- 無多語言或多模態能力
- 無顯式系統角色支援

---

### Meta 系列

#### LLaMA

| 版本 | 參數量 |
|-----|--------|
| **LLaMA** | 7B、13B、33B、65B |

**優點**：
- 13B 版本在多項基準上超越 GPT-3（175B），體積小 10 倍
- 65B 版本與 Chinchilla-70B 和 PaLM-540B 相當
- 開源，衍生出 Alpaca、Vicuna 等模型
- 可在消費級硬體上運行

**缺點**：
- 基礎模型，需要進一步微調
- 文檔仍在開發中

---

#### Llama 3

| 版本 | 特點 |
|-----|------|
| **8B** | 高效部署，超越 Gemma 7B 和 Mistral 7B |
| **70B** | 多數基準超越 Gemini Pro 1.5 和 Claude 3 Sonnet |

**優點**：
- 128K 詞彙表、15+ 兆 tokens 訓練
- 結合 SFT、拒絕採樣、RLHF、DPO 的後訓練
- 性能優異、開源可用

**缺點**：
- 數學任務（MATH 基準）表現不如 Gemini Pro 1.5
- 400B 版本仍在開發中
- 多模態和擴展上下文功能尚未發布

---

#### Code Llama

| 版本 | 用途 |
|-----|------|
| **Code Llama** | 基礎程式碼模型 |
| **Code Llama Python** | Python 專精 |
| **Code Llama Instruct** | 自然語言指令微調 |

**優點**：
- 程式碼補全、除錯、單元測試生成
- 文字轉 SQL
- Few-shot 學習處理 pandas dataframes

**缺點**：
- 70B Instruct 版本不支援函數調用
- 安全對齊可能導致模糊提示被拒絕
- 輸出一致性不穩定

---

### Mistral AI 系列

#### Mistral 7B

| 特點 | 說明 |
|-----|------|
| **參數量** | 70 億 |
| **授權** | Apache 2.0 |
| **注意力機制** | Grouped-query + Sliding window |

**優點**：
- 在所有評估基準上超越 Llama 2 13B
- 數學、程式碼生成、推理表現優異
- 達到 Code Llama 7B 的程式碼生成性能
- 適合即時應用

**缺點**：
- 容易產生幻覺
- 易受提示注入攻擊
- 參數量有限，知識儲存受限
- 未經提示注入和越獄測試

**使用建議**：使用系統提示執行安全防護；可作為內容審核器分類內容。

---

#### Mistral Large

| 特點 | 說明 |
|-----|------|
| **上下文窗口** | 32K tokens |
| **MMLU 分數** | 81.2%（僅次於 GPT-4）|
| **多語言** | 英、法、西、德、義 |

**優點**：
- 原生函數調用和 JSON 格式化
- 可自訂審核策略
- 推理、數學、程式碼能力強

**缺點**：
- 推理和知識基準明顯落後 GPT-4
- 編程挑戰表現不如 Gemini Pro 和 GPT-4
- 專業數學問題表現較弱

---

#### Mixtral 8x7B

| 特點 | 說明 |
|-----|------|
| **總參數** | 470 億（每 token 啟用 130 億）|
| **架構** | 稀疏混合專家（8 個專家組）|
| **授權** | Apache 2.0 |

**優點**：
- 匹配或超越 Llama 2 70B，參數更少
- 數學、程式碼、多語言理解優異
- 32K 上下文窗口，長範圍理解穩健
- Instral 版本在人類評估中超越 GPT-3.5 Turbo

**缺點**：
- 需要較大計算資源
- 一般 LLM 的通用限制

---

#### Mixtral 8x22B

| 特點 | 說明 |
|-----|------|
| **總參數** | 1410 億（啟用 390 億）|
| **上下文窗口** | 64K tokens |
| **GSM8K** | 90%（maj@8）|

**優點**：
- 多語言、數學推理、程式碼生成
- 原生函數調用、約束輸出生成
- MMLU、HumanEval 表現領先
- 性能/成本比優異

**缺點**：
- 模型較大，部署需要資源
- 文檔未詳述具體限制

---

### 其他模型

#### Phi-2（Microsoft）

| 特點 | 說明 |
|-----|------|
| **參數量** | 27 億 |
| **授權** | MIT |
| **特色** | 超越 25 倍大的模型 |

**優點**：
- 多步推理、常識推理優異
- Python 程式碼生成
- 數學和物理問題求解
- 無需 RLHF，依靠「教科書品質數據」

**缺點**：
- 可能生成不準確的程式碼和陳述
- 無指令微調時表現較差
- 傾向生成冗長回應
- 非英語和俚語理解較弱
- 可能產生偏見或有毒內容

---

#### Flan（Google）

**優點**：
- 零樣本推理：「let's think step-by-step」激活
- 多語言表現：TyDiQA 提升 14.9%
- 數學推理：CoT + Self-Consistency 達最先進水準
- Flan-T5 超越標準 T5

**缺點**：
- 任務數量擴展收益遞減
- 某些指令跟隨任務零樣本表現有差距

---

#### Grok-1（xAI）

| 特點 | 說明 |
|-----|------|
| **參數量** | 3140 億（啟用 25%）|
| **授權** | Apache 2.0 |
| **知識截止** | 2023 年 10 月 |

**優點**：
- HumanEval 63.2%、MMLU 73%
- 超越 ChatGPT-3.5 和 Inflection-1
- 推理和編程任務能力強

**缺點**：
- 原始預訓練檢查點，未針對特定應用微調
- 落後 GPT-4 等改進模型
- 需要多 GPU 部署
- 回應不如生產級模型精煉

---

#### OLMo（Allen AI）

| 特點 | 說明 |
|-----|------|
| **參數量** | 1B、7B |
| **授權** | Apache 2.0 |
| **訓練數據** | Dolma（3 兆 tokens）|

**優點**：
- 常識推理評估中 8/9 任務排名前 3
- 完全開放：數據、訓練程式碼、模型、評估程式碼
- 支援協作研究和可重現性

**缺點**：
- 提示指南仍在開發中
- 社群和文檔較小

---

#### Sora（OpenAI）

| 特點 | 說明 |
|-----|------|
| **類型** | 文字轉視頻生成模型 |
| **技術** | 擴散 + Transformer |
| **能力** | 生成最長 1 分鐘的逼真視頻 |

**優點**：
- 創建複雜場景、多角色、不同運動類型
- 維持多鏡頭視覺一致性
- 從靜態圖像生成視頻
- 使用 DALL·E 3 的重新描述技術

**缺點**：
- 難以準確模擬物理
- 因果關係理解困難
- 有時誤解空間細節和事件描述
- 相機移動指示可能被誤解
- 目前僅限特定測試人員使用

---

### 模型選擇指南

| 使用場景 | 推薦模型 |
|---------|---------|
| **低成本大規模對話** | GPT-3.5-turbo、Mistral 7B |
| **高品質推理** | GPT-4、Claude 3 Opus |
| **超長文本處理** | Claude 3、Gemini 1.5 Pro |
| **程式碼生成** | Code Llama、GPT-4、Mixtral |
| **多模態任務** | GPT-4 Vision、Gemini、Claude 3 |
| **開源自部署** | Llama 3、Mistral、Mixtral |
| **設備端運行** | Gemini Nano、Phi-2、Gemma 2B |
| **研究透明度** | OLMo |
| **視頻生成** | Sora |

---

### 模型能力快速對照表

| 模型 | 參數量 | 上下文 | 多模態 | 開源 | 主要優勢 |
|------|--------|--------|--------|------|----------|
| GPT-4 | 未公開 | 128K | ✓ | ✗ | 推理、對齊 |
| Claude 3 Opus | 未公開 | 200K+ | ✓ | ✗ | 長文本、準確性 |
| Gemini 1.5 Pro | 未公開 | 1M | ✓ | ✗ | 超長上下文 |
| Llama 3 70B | 700 億 | 8K | ✗ | ✓ | 開源性能 |
| Mixtral 8x22B | 1410 億 | 64K | ✗ | ✓ | 效率、多語言 |
| Mistral 7B | 70 億 | 32K | ✗ | ✓ | 輕量高效 |
| Phi-2 | 27 億 | - | ✗ | ✓ | 極小高效 |

---

## 測試環境說明

本指南中的所有範例都使用 OpenAI 的 Playground 以 `gpt-3.5-turbo` 進行測試（除非另有說明），採用預設設置：
- `temperature = 1`
- `top_p = 1`

---

## 總結

Prompt 工程是一門需要不斷實踐和迭代的技能。關鍵要點包括：

1. **從簡單開始**，逐步增加複雜度
2. **清晰具體**地表達你的需求
3. **善用各種技術**，根據任務選擇合適的方法
4. **持續實驗**，找出最適合你使用情境的方法

無論是基本的零樣本提示，還是進階的 RAG 和 ReAct 框架，選擇正確的技術可以顯著提升 LLM 的輸出品質。

---

*本文翻譯整理自 Prompt Engineering Guide (https://www.promptingguide.ai/)*
